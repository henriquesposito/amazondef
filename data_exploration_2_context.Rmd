---
title: "Amazon in Presidential Speeches in Brazil: data exploration for contexts"
author: "Henrique Sposito and Livio Silva-Muller"
date: "10/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data and Filter it for Amazon related portions in texts

```{r amazon, warning=FALSE, message=FALSE}
library(dplyr)
library(stringi)
library(tm)
library(ggplot2)

# Load data
BR_Presidential_Speeches <- readRDS("~/GitHub/amazondef/BR_Presidential_Speeches.Rds")
# Subset for text matches
Amazon_speeches <- dplyr::filter(BR_Presidential_Speeches, grepl("Amazôn|Amazon|amazôn|amazon", text))
# Remove accents and extra spaces
Amazon_speeches$text <- stringi::stri_trans_general(Amazon_speeches$text, id = "Latin-ASCII")
# Make all lower case
Amazon_speeches$text <- tolower(Amazon_speeches$text)
# Remove extra white spaces
Amazon_speeches$text <- tm::stripWhitespace(Amazon_speeches$text)
# Get only the pertinent text chunks
Amazon_speeches$context <- poldis::context("amazon", var = Amazon_speeches$text, level = "sentences")
# Transform into a single text per row...
Amazon_speeches$ccontext <- unlist(lapply(Amazon_speeches$context, function(x) paste(x, collapse = " | ")))

# In case you want to sample a few ramdom text observations by president
# sample_pres <- Amazon_speeches %>% group_by(president) %>% sample_n(8) %>% select(president, year, ccontext)

# Create a littale frequencies data frame
freq_year <- data.frame(year = as.numeric(names(summary(as.factor(Amazon_speeches$year)))),
                        freq = as.numeric(summary(as.factor(Amazon_speeches$year))),
                        freqn = as.numeric(summary(as.factor(Amazon_speeches$year)))/
                          as.numeric(summary(as.factor(BR_Presidential_Speeches$year))))

# Simple plot of the frequncy of speeches that mention Amazon since 1985
plot(freq_year$year, freq_year$freq, type = "b",
     main = "Presidential Speeches that mention the Amazon since 1985 in Brazil",
     xlab = "Year", ylab = "Frequency")

# Plot number of speeches that mention Amazon normalized by the number of speeches per year in broader data
plot(freq_year$year, freq_year$freqn, type = "b",
     main = "Presidential Speeches that mention the Amazon since 1985 in Brazil",
     sub = "Normalized by the number of speeches per year in broader dataset",
     xlab = "Year", ylab = "Frequency")

# Also, let's load the data on annual rates of deforestation in the Brazilian Amazon per year
amazon_def_year <- readRDS("~/GitHub/amazondef/amazon_def_year.Rds")
freq_year <- dplyr::left_join(freq_year, amazon_def_year, by = "year")
ggplot(freq_year, aes(x = year)) +
    geom_line(aes(y = freqn, color = "Frequency of amazonian speeches")) +
    geom_line(aes(y = `area km²`/100, color = "Annual deforestation (km²/100)")) +
      labs(x = "Year",
       y = "",
       title = "Presidential Speeches that Mention the Amazon since 1985 in Brazil",
       subtitle = "Compared to annual deforestation rates since 1988",
       caption = "Frequencies are normalized by the number of speeches per year in dataset",
       color = "Legend")
```

We start by subsetting the broad dataset it for the texts that mention the strings "Amazon" in it as a word or parts of words. Then, we us `{poldis}` to get the context for each mention of the "Amazon", by default one sentence before and one sentence after the sentence in which the string "Amazon" is matched.

From the first plot, the proportion of speeches that mention the word "Amazon" increase in frequency in 1989 (possibly related to Amazon Fires coverage from the New York Times see [here](https://www.nytimes.com/1988/08/12/world/vast-amazon-fires-man-made-linked-to-global-warming.html) and [here](https://www.nytimes.com/1989/03/23/world/brazil-smarting-from-the-outcry-over-the-amazon-charges-foreign-plot.html)), around 1992 (likely related to the Rio Conference), from 2005 to 2010 (possibly related to the "preservation" legislation turn under the Lula Administration), and after 2016 (possibly related to increasing deforestation rates and international attention). Notice that the frequency is normalized by the number of speeches per year in the broader dataset.

The second plot also compares mentions of Amazon and annual deforestation rates for the Brazilian Amazon [here](http://terrabrasilis.dpi.inpe.br/app/dashboard/deforestation/biomes/legal_amazon/rates). We see that for later years (2005 and afterwards), it appears that as deforestation rates go down or up we also see, often, these trends reflected in the proportional frequency to which discourses about the Amazon takes place.

## Clean text and get most frequent terms overall, and by speaker, in time

```{r term frequency, warning=FALSE, message=FALSE}
library(tidytext)
library(kableExtra)
library(stringr)
library(wordcloud)
library(RColorBrewer)

# Rename variables to adapt to text analysis packages' expectations
Amazon_speeches <- dplyr::rename(Amazon_speeches, fulltext = text, text = ccontext)

# Remove stopwords and punctuation
Amazon_speeches$text <- tm::removePunctuation(Amazon_speeches$text)
Amazon_speeches$text <- tm::removeWords(Amazon_speeches$text,
                                        c(tm::stopwords("pt"), "nao", "amazonas",
                                          "amazonia", "governo", "amazonica", "ja", "aqui", "tambem",
                                          "no", "hoje", "presidente", "governador", "regiao", 
                                          "sao", "voces", "ser", "bem", "la", "so", "desta", "porque",
                                          "fazer", "quero", "ter", "vamos", "the", "of", "ha", "ai",
                                          "ate", "vai", "dizer", "estao", "it", "ver", "r", "	it",
                                          "cumprimentar", "gente", "estado", "querido", "queria",
                                          "todos", "brasil"))
Amazon_speeches$text <- stringr::str_remove_all(Amazon_speeches$text, " [a-z] ")

# Transform into corpus
Amazon_speeches <- Amazon_speeches %>%
  dplyr::mutate(doc_id = president) %>%
  arrange(doc_id, text)
amazon_corpus <- tm::VCorpus(DataframeSource(Amazon_speeches))

# Get 30 most frequent words overall
amazon_dtm  <- DocumentTermMatrix(amazon_corpus)
amazon_dtmm <- as.matrix(amazon_dtm)
amazon_f <- data.frame(term = names(colSums(amazon_dtmm)),
                       freq = colSums(amazon_dtmm))
amazon_f <- amazon_f[order(amazon_f$freq, decreasing = T),]
rownames(amazon_f) <- NULL
amazon_f30 <- data.frame(head(amazon_f, 30))
amazon_f30
# Just plot in a wordcloud for words
set.seed(1234)
wordcloud(words = amazon_f$term, freq = amazon_f$freq, min.freq = 50,
          max.words=200, random.order = FALSE, rot.per=0.35, 
          colors = brewer.pal(8, "Dark2"))

# Let's see if bigrams help us more here
tamazon <- tidytext::tidy(amazon_corpus) %>%
  unnest_tokens(bigram, text , token = "ngrams", n = 2) %>%
  dplyr::count(bigram, sort = TRUE) %>%
  ungroup()
tamazon
# A plot in a wordcloud for bigrams
set.seed(1234)
wordcloud(words = tamazon$bigram, freq = tamazon$n, min.freq = 20,
          max.words=200, random.order = FALSE, rot.per=0.35, 
          colors = brewer.pal(8, "Dark2"))

# Let's get the 30 most frequent term by speaker
amazon_presid <- aggregate(Amazon_speeches$text, list(Amazon_speeches$president), paste, collapse = " ") %>%
  rename(doc_id = "Group.1", text = "x")
amazon_presid_t <- tm::VCorpus(DataframeSource(amazon_presid)) %>%
  tidy() %>% 
  unnest_tokens(word, text) %>%
  count(id, word, sort = TRUE)
Sarney <- head(dplyr::filter(amazon_presid_t, id == "Sarney"), 30) %>%
  mutate(Sarney = word) %>% select(Sarney)
Collor <- head(dplyr::filter(amazon_presid_t, id == "Collor"), 30) %>%
  mutate(Collor = word) %>% select(Collor)
Itamar <- head(dplyr::filter(amazon_presid_t, id == "Itamar"), 30) %>%
  mutate(Itamar = word) %>% select(Itamar)
FHC <- head(dplyr::filter(amazon_presid_t, id == "FHC"), 30) %>%  mutate(FHC = word) %>% select(FHC)
Lula <- head(dplyr::filter(amazon_presid_t, id == "Lula"), 30) %>%  mutate(Lula = word) %>% select(Lula)
Dilma <- head(dplyr::filter(amazon_presid_t, id == "Dilma"), 30) %>%  mutate(Dilma = word) %>% select(Dilma)
Temer <- head(dplyr::filter(amazon_presid_t, id == "Temer"), 30) %>%  mutate(Temer = word) %>% select(Temer)
Bolsonaro <- head(dplyr::filter(amazon_presid_t, id == "Bolsonaro"), 30) %>%
  mutate(Bolsonaro = word) %>% select(Bolsonaro)
f_speaker <- cbind(Sarney, Collor, Itamar, FHC, Lula, Dilma, Temer, Bolsonaro) %>% 
  kableExtra::kbl(caption = "Top 10 Words Per President") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")
f_speaker
```

After cleaning the text we start by getting word frequencies. Although word frequencies do not seem very helpful, more interesting patterns start to appear with bigrams 82 words that appear together) as we see, for example, "meio ambiente" (environment) appear central alongside references to the Amazonian forest, the tax free zone in Manaus (capital of the state of Amazonas), and references to other countries ("outros paises").

When it comes to the 30 most frequent words per speaker, we see more interesting patterns as words such as development (all presidents but Temer), integration (Collor and Itamar), security (Temer), deforestation (Lula, Dilma, and Temer), among others.

## Simple LDA model by speakers

```{r lda, warning=FALSE, message=FALSE}
library(topicmodels)

# Fit a simple LDA model
# Please note that we randomly set a K = 10 (10 cluster = topics)
amazon_lda <- topicmodels::LDA(amazon_dtm, k = 10, control = list(seed = 1234))

# Get the top 10 words per topic
amazon_lda10 <- tidy(amazon_lda, matrix = "beta") %>%
  arrange(desc(beta)) %>%
  group_by(topic) %>%
  filter(row_number() %in% 1:10) %>%
  arrange(topic)
topten_topic <- aggregate(amazon_lda10$term, list(amazon_lda10$topic), paste, collapse=", ") %>%
  rename(Topic = "Group.1", Terms = "x") %>% 
  kableExtra::kbl(caption = "Top 10 Words per Topic for Presidential Speeches Mentioning the Amazon") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")
topten_topic

# Let's get the gamma (percent of topic in document for speakers)
amazon_lda_presid <- tidy(amazon_lda, matrix = "gamma") %>%
  arrange(desc(gamma)) %>%
  group_by(document) %>%
  filter(row_number() %in% 1:2) %>% # get the top 3 topics per speaker
  arrange(document) %>%
  mutate(gamma = round(gamma, 3)) %>%
  distinct() %>% 
  rename (president = document) %>% 
  kableExtra::kbl(caption = "Top 2 Topics Per Speaker") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")
amazon_lda_presid # Only Collor associated with topic cluster that mentions "ambiente"...
```

When it comes to the LDA (Latent Dirichlet allocation), which is a model for estimating the mixture of words associated with a topic (cluster) and determining the probabilities of topics in each document, we start to see some interesting patterns (for more information on LDA and R approaches [here](https://www.tidytextmining.com/index.html)). We set the number of clusters to be found (topics) at 10, randomly. We, then, select the top ten words coded for each topic. The first three topics relate to themes of security, development, and integration. The fourth topic relates to themes of deforestation and sustainable development. Topics five to nine appear to relate to themes of politics, energy, and geography. The last topic appears to relate to themes of preservation of the Amazonian forest.

Once the clusters are extracted, we can indicate, probabilistically, how presidents' discourse fall within a topic. We see that, for example, Lula's discourses about the Amazon often is clustered with themes of development and of deforestation. At the same time, Bolsonaro's discourses about the Amazon often is clustered with themes of integration, energy, and the military forces. Sarney engaged with themes of preservation, while Cardoso engages with themes related to energy and integration. Others as Rousseff and Temer appear to engage with themes of geography, politics, energy; while Collor an Itamar appear to engage with themes of security, development, and integration.

## Get, and compare, sentiment in time for speakers (Afinn and NRC)

```{r sentiment, warning=FALSE, message=FALSE}
library(stringr)
# library(poldis)

# Load internal sentiment dictionaries from poldis
Afinn_pt <- poldis:::Afinn_pt
nrc_portuguese <- poldis:::nrc_portuguese

# Aggregate by president and year and transform into a corpus
amazon_sent <- mutate(Amazon_speeches, doc_id = paste0(doc_id, "_", year))
amazon_sent <- aggregate(amazon_sent$text, list(amazon_sent$doc_id), paste, collapse =" ") %>%
  rename(doc_id = "Group.1", text = "x") %>% 
  mutate(char = nchar(text))
amazon_sent_wf <- VCorpus(DataframeSource(amazon_sent)) %>%
  tidy() %>%
  unnest_tokens(word, text) %>%
  count(id, word, sort = TRUE)

# Get afinn sentiment
amazon_sent_af <- inner_join(amazon_sent_wf, Afinn_pt, by = "word") %>%
  group_by(id) %>%
  summarize(value = sum(n)) %>%
  mutate(year = stringr::str_extract(id, "[0-9]{4}"),
         president = stringr::str_remove_all(id, "_[0-9]{4}"),
         date2 = stringr::str_extract(id, "[0-9]{2}$"),
         nvalue = value/amazon_sent$char)

# Plot Afinn sentiment in time for speeches about the Amazon
ggplot(amazon_sent_af, aes(x = reorder(date2, as.numeric(year)), y = nvalue , fill = president)) +
  geom_line(aes(group = president)) +
  geom_point(size = 5, shape = 21) +
  labs(x = "",
       y = "",
       title = "Sentiment in Presidential Speeches about the Amazon",
       subtitle = "Normalized by the number of characters in text for speaker",
       caption = "Afinn sentiment lexicon")

# Get NRC per speaker
amazon_sent_nrc <- inner_join(amazon_sent_wf, nrc_portuguese, by = "word") %>%
  filter(sentiment != "positive", sentiment != "negative") %>% 
  # removing positive and negative for more informative results
  group_by(id, sentiment) %>%
  summarize(value = sum(n)) %>%
  mutate(year = stringr::str_extract(id, "[0-9]{4}"),
         president = stringr::str_remove_all(id, "_[0-9]{4}"),
         date2 = stringr::str_extract(id, "[0-9]{2}$"))
# Normalize (first you have to multiple each speaker value 8 times)
char <- select(amazon_sent, -text) %>% rename(id = doc_id)
amazon_sent_nrc <- left_join(amazon_sent_nrc, char, by = "id") %>%
  mutate(nvalue = (value/char)*100000)

# Plot NRC
ggplot(amazon_sent_nrc, aes(x = reorder(id, as.numeric(year)), y = nvalue, fill = sentiment)) +
  geom_bar(position="stack", stat="identity") +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=1)) +
  labs(x = "",
       y = "",
       title = "Sentiment in Presidential Speeches about the Amazon",
       subtitle = "Normalized by the number of characters in text for speaker",
       caption = "NRC sentiment lexicon") +
  coord_flip() +
  expand_limits(y=c(0, 1000))
```

The Afinn sentiment lexicon gets to the polarity of certain words coded by assigning a value to them, positive and negative. The scores are normalized by the number of characters in text data for speaker per year. This allow us to compare the average use of charged words coded for with the sentiment lexicon for each speaker per year. We see in the plot, for example, that Sarney from 1985-87 employs more positive words coded for sentiment on speeches that mention the Amazon than other presidents. The same can be said about Bolsonaro who used more positively charged words on average than other presidents when speaking about the Amazon according to the lexicon. Other presidents, as Cardoso, Rousseff and Lula appear more consistent in time in regards to the average polarity of terms used in Amazonian related discourses than Temer, Collor, and Itamar.

The NRC sentiment lexicon codes different sentiment for certain words. The scores for each of the sentiments coded also are normalized by the number of characters in text data for speaker per year. This allow us to compare the sentiments used according to the sentiment lexicon for each speaker per year. We see in the plot, that Lula in the early 2000s used many words coded for "trust" when speaking about the Amazon on average than other presidents/years. As well, Itamar in 1992 appeared to use more words coded for "anger" and "fear" on average than other presidents/years. 

## Does location matter?

```{r location, warning=FALSE, message=FALSE}
# Location was added with poldis::extraxt_location(), still needs to be improved...
# To see the variable summary, please run: `summary(as.factor(Amazon_speeches$location))`
# Let's code the Amzonian states, the other Brazilian states, and speeches delivered outside Brazil.
Amazon_lc <- mutate(Amazon_speeches, stage = case_when(grepl("Amazonas|Para|Roraima|Acre|Amapa|Rondonia|Mato-Grosso|Tocantins|Maranhao", location) ~ "Amazonian_States", grepl("Alagoas|Bahia|Ceará|Distrito Federal|Goias|Minas Gerais|Espirito Santo|Paraiba|Parana|Pernambuco|Piaui|Rio de Janeiro|Rio Grande do Norte|Rio Grande do Sul|Santa Catarina|Sao Paulo|Brazil|Sergipe", location) ~ "Non_Amazonian_States", grepl("NA", location) ~ "Non_Identified", !grepl("Amazonian_States|Non_Amazonian_States|Non_Identified", location) ~ "International"))
summary(as.factor(Amazon_lc$stage)) # A lot of missing observations still ...
# Just a comparison with the proprtion of speeches per stage on the broader dataset
stages <- mutate(BR_Presidential_Speeches, stage = case_when(grepl("Amazonas|Para|Roraima|Acre|Amapa|Rondonia|Mato-Grosso|Tocantins|Maranhao", location) ~ "Amazonian States", grepl("Alagoas|Bahia|Ceará|Distrito Federal|Goias|Minas Gerais|Espirito Santo|Paraiba|Parana|Pernambuco|Piaui|Rio de Janeiro|Rio Grande do Norte|Rio Grande do Sul|Santa Catarina|Sao Paulo|Brazil|Sergipe", location) ~ "Non Amazonian States", grepl("NA", location) ~ "Non Identified", !grepl("Amazonian States|Non Amazonian States|Non Identified", location) ~ "International"))
stage_rate <- data.frame(Stage = names(summary(as.factor(Amazon_lc$stage))),
                         Amazon_speeches = paste0(round(as.numeric(summary(as.factor(Amazon_lc$stage))/861)*100, 2)," %"),
                         All_speeches = paste0(round(as.numeric(summary(as.factor(stages$stage))/6088)*100, 2)," %"))
stage_rate

# Let's try an simple LDA model again
Amazon_lc <- mutate(Amazon_lc, doc_id = stage) %>% arrange(doc_id, text)
amazon_lcc <- tm::VCorpus(DataframeSource(Amazon_lc))
amazon_dtm_lc  <- DocumentTermMatrix(amazon_lcc)
amazon_lda_lc <- topicmodels::LDA(amazon_dtm_lc, k = 10, control = list(seed = 1234)) # set k = 10
amazon_lda_lcc <- tidy(amazon_lda_lc, matrix = "beta") %>%
  arrange(desc(beta)) %>%
  group_by(topic) %>%
  filter(row_number() %in% 1:10) %>%
  arrange(topic)
topten_lc <- aggregate(amazon_lda_lcc$term, list(amazon_lda_lcc$topic), paste, collapse=", ") %>%
  rename(Topic = "Group.1", Terms = "x")

# Get stage and merge tables
amazon_lda_lcs <- tidy(amazon_lda_lc, matrix = "gamma") %>%
  arrange(desc(gamma)) %>%
  group_by(document) %>%
  filter(row_number() %in% 1:3) %>% # get the top 3 topics per location
  arrange(document) %>% 
  select(-gamma) %>% 
  distinct()
amazon_lda_topic <- aggregate(amazon_lda_lcs$document, list(amazon_lda_lcs$topic), paste, collapse = ", ") %>% rename(Topic = "Group.1", Stage = "x") 
amazon_lda_topic <- dplyr::left_join(topten_lc, amazon_lda_topic, by = "Topic") %>%
  kableExtra::kbl(caption = "Top 10 Words per Topic for Stages") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")
amazon_lda_topic


```

The summary table illustrates that, as expected, more speeches that mention the Amazon proportionally take place in Amazonian states in comparison to their proportion in all speeches. However, when it comes ot international settings, a lower proportion of the speeches that mention the Amazon take place in international settings in comparison to all speeches.

We can also get the themes by setting for each of the ten topics (clusters) generated with the LDA. We see, for example, that some of the themes related to cooperation and integration appear in Amazonian States and Non Identified stages (topic 2). While themes related to development, deforestation, and sustainability appear in International stages (topic 4). Interestingly, themes related to preservation of the forest appear in Amazonian states and Non Amazonian States.

# Let's try and categorize the texts into narratives ...

In this preliminary approach we attempt to count and show correlations between coded narratives, presidents, and stages.

```{r narratives, warning=FALSE, message=FALSE}
# Create the dictionary
sovereignty <- ("amazonia e brasileira|amazonia e nossa|soberania|interesse estrangeiro|ocupar|forcas armadas|militar|fronteir|patrimonio|nacional|defesa|exercito")
development <- ("estrada|rodovia|hidroeletrica|desenvolv|balbina|itaipu|incentivos fiscais|integrar|integracao|zona franca|transamazonica|madeira|porto")
conservation <- ("preserv|conserv|determinacao|povos indigenas|indigenas|direitos humanos|areas demarcadas|queimada|sustentav|meio ambiente|florest")
anti_environmentalism <- ("preservamos demais|nao vamos demarcar|demarcar menos|agricultura|producao de gado") # This appears harder to operationalize than others...

# Create a variable for each and count matches
Amazon_speeches$sovereignty <- stringr::str_count(Amazon_speeches$text, paste0("(?i)", sovereignty))
Amazon_speeches$development <- stringr::str_count(Amazon_speeches$text, paste0("(?i)", development))
Amazon_speeches$conservation <- stringr::str_count(Amazon_speeches$text, paste0("(?i)", conservation))
Amazon_speeches$anti_environmentalism <- stringr::str_count(Amazon_speeches$text,
                                                            paste0("(?i)", anti_environmentalism))
Amazon_speeches$other <- ifelse(Amazon_speeches$sovereignty == 0 & Amazon_speeches$development == 0 & 
                                  Amazon_speeches$conservation == 0 & 
                                  Amazon_speeches$anti_environmentalism == 0, 1, 0)

# Visualize correlations
ggplot(Amazon_speeches, aes(x = year)) +
  geom_line(aes(y = sovereignty, color = "Sovereignty")) +
  geom_line(aes(y =  development, color = "Development")) +
  geom_line(aes(y =  conservation, color = "Conservation")) +
  geom_line(aes(y =  anti_environmentalism, color = "Anti_environmentalism")) +
      labs(x = "Year",
       y = "",
       title = "Narratives in Presidential Speeches per year since 1985 in Brazil",
       color = "Narrative")

# Narrative per president, frequency table
pres_narratives <- Amazon_speeches %>%
  select(-c(context, text, fulltext, year, party, date, title, doc_id, location)) %>%
  group_by(president) %>%
  summarise(across(everything(), sum))
kableExtra::kbl(pres_narratives, caption = "Narratives per President in Brazil") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")

# Same frequency table but normalized by the numbers of speeches in broader dataset
pres_narratives_n <- pres_narratives %>%
  mutate(n_speeches = summary(as.factor(BR_Presidential_Speeches$president))) %>%
  mutate(across(c(2:6), .fns = ~./n_speeches)) %>%
  select(-n_speeches) %>%
  mutate_if(is.numeric, round, digits = 2)
kableExtra::kbl(pres_narratives_n, caption = "Narratives per President in Brazil (normalized)") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")

# Table by stage
stage_narratives <- Amazon_speeches %>%
  mutate(stage = Amazon_lc$stage) %>%
  select(-c(context, text, fulltext, year, party, date, title, doc_id, location, president)) %>%
  group_by(stage) %>%
  summarise(across(everything(), sum))
kableExtra::kbl(stage_narratives, caption = "Narratives per President in Brazil") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")

# Table by stage, normalized
stage_narratives_n <- stage_narratives %>%
  mutate(n_stages = summary(as.factor(Amazon_lc$stage))) %>%
  mutate(across(c(2:6), .fns = ~./n_stages)) %>%
  select(-n_stages) %>%
  mutate_if(is.numeric, round, digits = 2)
kableExtra::kbl(stage_narratives_n, caption = "Narratives per President in Brazil (normalized)") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Times New Roman")
```

While the dictionary of terms needs to be greatly expanded to operationalize narratives in discourse, we see that some narratives appear more than others in certain periods, often in unexpected years. This is specially puzzling as conservationism narratives peak in the late 1980s, sovereignty narratives in the mid 1990s and development narratives in the early 2000s. 

Moreover, as the first few plots at the beginning of the document illustrated, Amazon related speeches during the Sarney administration were salient as a proportional of the general numbers of speeches for the president in the dataset. at the same time. we see that Sarney engages with narratives of sovereignty, development, and conservation. Other presidents as Itamar and Cardoso engage overwhelmingly with development related narratives, while Collor and Bolsonaro engage with conservation (though, at least in the case of Bolsonaro, I believe the dictionary is matching negative cases and it needs be improved...).

When it comes to stage, all narratives are proportionally more salient within Amazonian states, as it would be expected. Anti-environmentalism appears slightly less in international stages in comparison to others.
